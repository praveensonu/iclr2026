{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fc857b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d714300",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992363ea",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import Dataset, load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from template import LLAMA3_CHAT_TEMPLATE\n",
    "from peft import PeftModel\n",
    "from config import Config2, Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8126741",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/wpu_data/retain_100.csv')\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb7df36",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Calculates EL2N scores\n",
    "\n",
    "def get_el2n_scores(model, tokenizer, question, answer):\n",
    "    \n",
    "    templated_question = LLAMA3_CHAT_TEMPLATE.format(question = question)\n",
    "    prompt = f\"{templated_question}{answer}{tokenizer.eos_token}\"\n",
    "\n",
    "    # tokenize without the answer\n",
    "    inputs_no_answer = tokenizer(templated_question, return_tensors='pt').to(model.device)\n",
    "    full_input_ids_no_answer = inputs_no_answer.input_ids[0].tolist()\n",
    "\n",
    "    # tokenize with the answer\n",
    "    inputs_full = tokenizer(prompt, return_tensors = 'pt').to(model.device)\n",
    "    full_input_ids_full = inputs_full.input_ids[0].tolist()\n",
    "\n",
    "\n",
    "    # Find the start index of the answer tokens within the full prompt's token IDs\n",
    "    start_index = -1\n",
    "    min_len = min(len(full_input_ids_no_answer), len(full_input_ids_full))\n",
    "    for i in range(min_len):\n",
    "        if full_input_ids_no_answer[i] != full_input_ids_full[i]:\n",
    "            start_index = i\n",
    "            break\n",
    "\n",
    "    if start_index == -1 and len(full_input_ids_full) > len(full_input_ids_no_answer):\n",
    "        start_index = len(full_input_ids_no_answer)\n",
    "    elif start_index == -1:\n",
    "        print(f\"Warning: Could not find the start of the answer in the prompt for question: {question[:50]}...\")\n",
    "        print(\"Full Input IDs (Full):\", full_input_ids_full)\n",
    "        print(\"Full Input IDs (No Answer):\", full_input_ids_no_answer)\n",
    "        return 0.0\n",
    "\n",
    "    labels = inputs_full.input_ids.clone()\n",
    "    # Mask out tokens before the start of the answer\n",
    "    labels[0, :start_index] = -100\n",
    "\n",
    "    with torch.no_grad():\n",
    "      outputs = model(**inputs_full, labels = labels)\n",
    "      logits = outputs.logits\n",
    "\n",
    "    logits_start_index = max(0, start_index - 1)\n",
    "    \n",
    "    logits_for_answer = logits[0, logits_start_index: -1, :]\n",
    "\n",
    "    labels_for_answer = labels[0, start_index: ]\n",
    "\n",
    "    valid_label_mask_answer = labels_for_answer != -100\n",
    "    valid_labels = labels_for_answer[valid_label_mask_answer]\n",
    "\n",
    "    if valid_labels.numel() == 0:\n",
    "\n",
    "      print(\"Warning: No valid labels found in the answer segment.\")\n",
    "      return 0.0\n",
    "    \n",
    "    valid_logits = logits_for_answer[valid_label_mask_answer]\n",
    "\n",
    "    if valid_logits.shape[0] != valid_labels.shape[0]:\n",
    "        print(\"Error: Mismatch between the number of valid logits and labels.\")\n",
    "        return 0.0\n",
    "    \n",
    "    probs = F.softmax(valid_logits, dim = -1)\n",
    "\n",
    "    one_hot_labels = F.one_hot(valid_labels, num_classes = probs.shape[-1]).float()\n",
    "\n",
    "    l2_norms = torch.norm(probs - one_hot_labels, p=2, dim=-1)\n",
    "\n",
    "    el2n_score = l2_norms.mean().item()\n",
    "\n",
    "    return el2n_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0fd88b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_grand_data_top(percent_to_keep_top):\n",
    "    n_total = len(dataset)\n",
    "    start_index_top = n_total - int(n_total * percent_to_keep_top)\n",
    "    grand_top = dataset.select(range(start_index_top, n_total))\n",
    "    return grand_top"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dacad3",
   "metadata": {},
   "source": [
    "## For WPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d5c23a",
   "metadata": {},
   "source": [
    "### With Gradient Descent Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42e3fd8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_id = 'path/to/check_point_gradient_descent_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d07829",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8964b99b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "example_scores = []\n",
    "\n",
    "for example in dataset:\n",
    "    scores = get_el2n_scores(model, tokenizer, example['question'], example['answer'])\n",
    "    example_scores.append(scores)\n",
    "\n",
    "\n",
    "dataset = dataset.add_column('el2n_score', example_scores)\n",
    "end_time = time.time() \n",
    "\n",
    "print(f\"Time taken: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd33f70e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset = dataset.sort('el2n_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d5b3ef",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_grand_data_top(percent_to_keep_top):\n",
    "    n_total = len(dataset)\n",
    "    start_index_top = n_total - int(n_total * percent_to_keep_top)\n",
    "    grand_top = dataset.select(range(start_index_top, n_total))\n",
    "    return grand_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865723ed",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "grand_desc_top_50 = get_grand_data_top(0.5)\n",
    "print(grand_desc_top_50.shape)\n",
    "\n",
    "grand_desc_top_10 = get_grand_data_top(0.1)\n",
    "print(grand_desc_top_10.shape)\n",
    "\n",
    "grand_desc_top_20 = get_grand_data_top(0.2)\n",
    "print(grand_desc_top_20.shape)\n",
    "\n",
    "grand_desc_top_5 = get_grand_data_top(0.05)\n",
    "print(grand_desc_top_5.shape)\n",
    "\n",
    "grand_desc_top_2 = get_grand_data_top(0.02)\n",
    "print(grand_desc_top_2.shape)\n",
    "\n",
    "grand_desc_top_1 = get_grand_data_top(0.01)\n",
    "print(grand_desc_top_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39434d77",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "grand_desc_top_50.to_csv('./data/wpu_data/coresets/grand/grad_descent/grand_desc_top_50.csv', index = False)\n",
    "grand_desc_top_10.to_csv('./data/wpu_data/coresets/grand/grad_descent/grand_desc_top_10.csv', index = False)\n",
    "grand_desc_top_20.to_csv('./data/wpu_data/coresets/grand/grad_descent/grand_desc_top_20.csv', index = False)\n",
    "grand_desc_top_5.to_csv('./data/wpu_data/coresets/grand/grad_descent/grand_desc_top_5.csv', index = False)\n",
    "grand_desc_top_2.to_csv('./data/wpu_data/coresets/grand/grad_descent/grand_desc_top_2.csv', index = False)\n",
    "grand_desc_top_1.to_csv('./data/wpu_data/coresets/grand/grad_descent/grand_desc_top_1.csv', index = False)\n",
    "\n",
    "dataset.to_csv('./data/wpu_data/coresets/grand/grad_descent/grand_desc_scores.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900c9a94",
   "metadata": {},
   "source": [
    "### With Gradient Difference Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a7adcf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_id = 'path/to/check_point_gradient_difference_model' #this is a peft model, so we need to concat the adapter. For descent we did it in the finetuning code already.\n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e388285a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(cfg.model_id)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(cfg.model_id, torch_dtype=torch.bfloat16, device_map='auto')\n",
    "model = PeftModel.from_pretrained(base_model, model_id, device_map='auto', torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c085788",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "example_scores = []\n",
    "\n",
    "for example in dataset:\n",
    "    scores = get_el2n_scores(model, tokenizer, example['question'], example['answer'])\n",
    "    example_scores.append(scores)\n",
    "\n",
    "\n",
    "dataset = dataset.add_column('el2n_score_gd', example_scores)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7a067a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset = dataset.sort('el2n_score_gd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e337020e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "grand_gd_top_50 = get_grand_data_top(0.5)\n",
    "print(grand_gd_top_50.shape)\n",
    "\n",
    "grand_gd_top_10 = get_grand_data_top(0.1)\n",
    "print(grand_gd_top_10.shape)\n",
    "\n",
    "grand_gd_top_20 = get_grand_data_top(0.2)\n",
    "print(grand_gd_top_20.shape)\n",
    "\n",
    "grand_gd_top_5 = get_grand_data_top(0.05)\n",
    "print(grand_gd_top_5.shape)\n",
    "\n",
    "grand_gd_top_2 = get_grand_data_top(0.02)\n",
    "print(grand_gd_top_2.shape)\n",
    "\n",
    "grand_gd_top_1 = get_grand_data_top(0.01)\n",
    "print(grand_gd_top_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34044870",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "grand_desc_top_50.to_csv('./data/wpu_data/coresets/grand/grad_diff/grand_diff_top_50.csv', index = False)\n",
    "grand_desc_top_10.to_csv('./data/wpu_data/coresets/grand/grad_diff/grand_diff_top_10.csv', index = False)\n",
    "grand_desc_top_20.to_csv('./data/wpu_data/coresets/grand/grad_diff/grand_diff_top_20.csv', index = False)\n",
    "grand_desc_top_5.to_csv('./data/wpu_data/coresets/grand/grad_diff/grand_diff_top_5.csv', index = False)\n",
    "grand_desc_top_2.to_csv('./data/wpu_data/coresets/grand/grad_diff/grand_diff_top_2.csv', index = False)\n",
    "grand_desc_top_1.to_csv('./data/wpu_data/coresets/grand/grad_diff/grand_diff_top_1.csv', index = False)\n",
    "\n",
    "dataset.to_csv('./data/wpu_data/coresets/grand/grad_diff/grand_diff_scores.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cbec25",
   "metadata": {},
   "source": [
    "## Unified data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5f5b74",
   "metadata": {},
   "source": [
    "### gradient difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe9b3a8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cfg = Config2() #config2 is for mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a144d922",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_id = 'path/to/check_point_gradient_difference_model'\n",
    "print(cfg.model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg.model_id)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(cfg.model_id, torch_dtype=torch.bfloat16, device_map='auto')\n",
    "model = PeftModel.from_pretrained(base_model, model_id, device_map='auto', torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536d0f53",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/mix/full_retain.csv')\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac147b0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "example_scores = []\n",
    "\n",
    "for example in dataset:\n",
    "    scores = get_el2n_scores(model, tokenizer, example['question'], example['answer'])\n",
    "    example_scores.append(scores)\n",
    "\n",
    "\n",
    "dataset = dataset.add_column('el2n_score_gd', example_scores)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41589f85",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset = dataset.sort('el2n_score_gd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f9ff6b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "diff_1 = get_grand_data_top(0.01)\n",
    "print(diff_1.shape)\n",
    "\n",
    "diff_2 = get_grand_data_top(0.02)\n",
    "print(diff_2.shape)\n",
    "\n",
    "diff_5 = get_grand_data_top(0.05)\n",
    "print(diff_5.shape)\n",
    "\n",
    "diff_10 = get_grand_data_top(0.1)\n",
    "print(diff_10.shape)\n",
    "\n",
    "diff_20 = get_grand_data_top(0.2)\n",
    "print(diff_20.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f117c63",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "diff_1.to_csv('./data/mix/coresets/grand/grad_difference/diff_1.csv', index = False)\n",
    "diff_2.to_csv('./data/mix/coresets/grand/grad_difference/diff_2.csv', index = False)\n",
    "diff_5.to_csv('./data/mix/coresets/grand/grad_difference/diff_5.csv', index = False)\n",
    "diff_10.to_csv('./data/mix/coresets/grand/grad_difference/diff_10.csv', index = False)\n",
    "diff_20.to_csv('./data/mix/coresets/grand/grad_difference/diff_20.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5674a34a",
   "metadata": {},
   "source": [
    "### With Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8001cd6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_id = 'path/to/check_point_gradient_descent_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294eba76",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68996353",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/mix/full_retain.csv')\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aadb45",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "example_scores = []\n",
    "\n",
    "for example in dataset:\n",
    "    scores = get_el2n_scores(model, tokenizer, example['question'], example['answer'])\n",
    "    example_scores.append(scores)\n",
    "\n",
    "\n",
    "dataset = dataset.add_column('el2n_score_gd', example_scores)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8362a5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset = dataset.sort('el2n_score_gd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8295f71",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "desc_1 = get_grand_data_top(0.01)\n",
    "print(desc_1.shape)\n",
    "\n",
    "desc_2 = get_grand_data_top(0.02)\n",
    "print(desc_2.shape)\n",
    "\n",
    "desc_5 = get_grand_data_top(0.05)\n",
    "print(desc_5.shape)\n",
    "\n",
    "desc_10 = get_grand_data_top(0.1)\n",
    "print(desc_10.shape)\n",
    "\n",
    "desc_20 = get_grand_data_top(0.2)\n",
    "print(desc_20.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d0814d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "desc_1.to_csv('./data/mix/coresets/grand/grad_descent/desc_1.csv', index = False)\n",
    "desc_2.to_csv('./data/mix/coresets/grand/grad_descent/desc_2.csv', index = False)\n",
    "desc_5.to_csv('./data/mix/coresets/grand/grad_descent/desc_5.csv', index = False)\n",
    "desc_10.to_csv('./data/mix/coresets/grand/grad_descent/desc_10.csv', index = False)\n",
    "desc_20.to_csv('./data/mix/coresets/grand/grad_descent/desc_20.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
