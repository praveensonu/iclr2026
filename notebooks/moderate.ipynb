{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f31e5f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0121ed",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e44bba9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "from tqdm import tqdm\n",
    "from config import Config2\n",
    "from template import LLAMA3_CHAT_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746d8c1c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_hidden_states(df, model, tokenizer, device, batch_size=1):\n",
    "    texts = (df['question_f'] + ' ' + df['answer_f']).tolist()\n",
    "    all_embeddings = []\n",
    "\n",
    "    model.eval()\n",
    "    print('Now extracting hidden reps')\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        inputs = tokenizer(\n",
    "            batch_texts,\n",
    "            padding = True,\n",
    "            truncation = True,\n",
    "            return_tensors = 'pt',\n",
    "            max_length = 256\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "        penultimate_hidden_states = outputs.hidden_states[-2]\n",
    "\n",
    "        seq_lens = inputs['attention_mask'].sum(dim=-1) - 1\n",
    "\n",
    "        batch_size_curr = penultimate_hidden_states.shape[0]\n",
    "\n",
    "        last_token_embeddings = penultimate_hidden_states[\n",
    "            torch.arange(batch_size_curr, device = model.device),\n",
    "            seq_lens\n",
    "        ].float().cpu().numpy()\n",
    "        all_embeddings.append(last_token_embeddings)\n",
    "\n",
    "    return np.vstack(all_embeddings)\n",
    "\n",
    "\n",
    "def get_reps(\n",
    "    df, model, tokenizer, device, batch_size=1):\n",
    "    \n",
    "    embeddings = get_hidden_states(df = df, model = model, tokenizer = tokenizer, device = device, batch_size = batch_size)\n",
    "\n",
    "    annotated_df = df.copy()\n",
    "\n",
    "    annotated_df['representation'] = list(embeddings)\n",
    "\n",
    "    return annotated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1290fcd9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def cluster_and_select_mod(\n",
    "    annotated_df:pd.DataFrame,\n",
    "    selection_percent : float,\n",
    "    n_clusters:int,\n",
    "    represent_col:str = 'representation'):\n",
    "\n",
    "    if not (0 < selection_percent <= 1.0):\n",
    "        raise ValueError(\"selection_percent must be between 0 and 1\")\n",
    "    \n",
    "    if len(annotated_df) < n_clusters:\n",
    "        raise ValueError(\"n_clusters must be less than the number of rows in df\")\n",
    "\n",
    "    embeddings = np.vstack(annotated_df[represent_col].tolist())\n",
    "\n",
    "    kmeans = KMeans(n_clusters = n_clusters, random_state = 42, n_init = 'auto')\n",
    "    cluster_labels = kmeans.fit_predict(embeddings)\n",
    "    centroids = kmeans.cluster_centers_\n",
    "\n",
    "    cluster_df = annotated_df.copy()\n",
    "    cluster_df['cluster'] = cluster_labels\n",
    "\n",
    "\n",
    "    # selecting samples closest to the median distance in each cluster\n",
    "\n",
    "    selected_indices = []\n",
    "    total_samples_to_select = int(len(cluster_df) * selection_percent)\n",
    "\n",
    "    print('Selecting samples closest to the median distance in each cluster...')\n",
    "\n",
    "    for i in range(n_clusters):\n",
    "        indices_in_cluster = np.where(cluster_labels == i)[0]\n",
    "        if len(indices_in_cluster) == 0:\n",
    "            continue\n",
    "\n",
    "        embeddings_in_cluster = embeddings[indices_in_cluster]\n",
    "        cluster_centroid  = centroids[i].reshape(1,-1)\n",
    "        distances = cdist(embeddings_in_cluster, cluster_centroid).flatten()\n",
    "        median_distance = np.median(distances)\n",
    "\n",
    "        distances_from_median = np.abs(distances - median_distance)\n",
    "        sorted_indices = indices_in_cluster[np.argsort(distances_from_median)]\n",
    "\n",
    "        proportion_of_cluster = len(indices_in_cluster) / len(cluster_df)\n",
    "        num_to_select_from_cluster = int(total_samples_to_select * proportion_of_cluster)\n",
    "        num_to_select_from_cluster = max(1, num_to_select_from_cluster) if len(indices_in_cluster) > 0 else 0\n",
    "\n",
    "        selected_indices.extend(sorted_indices[:num_to_select_from_cluster])\n",
    "    print(f\"Targeted {total_samples_to_select} samples, selected {len(selected_indices)}.\")\n",
    "    mod_df = cluster_df.iloc[selected_indices].copy()\n",
    "\n",
    "    return  cluster_df, mod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ba0c42",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1dd1b6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def make_template_format(df):\n",
    "     df['question_f'] = df['question'].apply(lambda x : LLAMA3_CHAT_TEMPLATE.format(question = x))\n",
    "     df['answer_f'] = df['answer'].apply(lambda x : x + tokenizer.eos_token)  \n",
    "     return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf42dc4e",
   "metadata": {},
   "source": [
    "### For WPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3a5104",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cfg = Config()\n",
    "df = pd.read_csv('./data/wpu_data/retain_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6fb460",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = make_template_format(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a716a33b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "full_rep_df = get_reps(df=df, model=model, tokenizer=tokenizer, device=device, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba4ab6f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "full_rep_df = full_rep_df[['title', 'question', 'answer', 'type', 'representation']]\n",
    "full_rep_df.head()\n",
    "\n",
    "df = full_rep_df.copy()\n",
    "df.to_parquet('./data/wpu_data/coresets/moderate/dta_reps_moderate.parquet', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f856becc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "_, mod_1 = cluster_and_select_mod(\n",
    "    annotated_df = full_rep_df,\n",
    "    selection_percent = 0.01,\n",
    "    n_clusters = 4,\n",
    ")\n",
    "\n",
    "_, mod_2 = cluster_and_select_mod(\n",
    "    annotated_df = full_rep_df,\n",
    "    selection_percent = 0.02,\n",
    "    n_clusters = 4,\n",
    ")\n",
    "\n",
    "_, mod_5 = cluster_and_select_mod(\n",
    "    annotated_df = full_rep_df,\n",
    "    selection_percent = 0.05,\n",
    "    n_clusters = 4,\n",
    ")\n",
    "\n",
    "_, mod_10 = cluster_and_select_mod(\n",
    "    annotated_df = full_rep_df,\n",
    "    selection_percent = 0.1,\n",
    "    n_clusters = 4,\n",
    ")\n",
    "\n",
    "_, mod_20 = cluster_and_select_mod(\n",
    "    annotated_df = full_rep_df,\n",
    "    selection_percent = 0.2,\n",
    "    n_clusters = 4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528054b9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "mod_1.to_csv('./data/wpu_data/coresets/moderate/mod_1.csv', index=False)\n",
    "mod_2.to_csv('./data/wpu_data/coresets/moderate/mod_2.csv', index=False)\n",
    "mod_5.to_csv('./data/wpu_data/coresets/moderate/mod_5.csv', index=False)\n",
    "mod_10.to_csv('./data/wpu_data/coresets/moderate/mod_10.csv', index=False)\n",
    "mod_20.to_csv('./data/wpu_data/coresets/moderate/mod_20.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f4d481",
   "metadata": {},
   "source": [
    "### Mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7277d6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_id = 'path/to/the/\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModel.from_pretrained(model_id, torch_dtype=torch.bfloat16)\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382be5a7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/mix/full_retain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a482a2bc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_hidden_states(df, model, tokenizer, device, batch_size=1):\n",
    "    texts = (df['question_f'] + ' ' + df['answer_f']).tolist()\n",
    "    all_embeddings = []\n",
    "\n",
    "    model.eval()\n",
    "    print('Now extracting hidden reps')\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        inputs = tokenizer(\n",
    "            batch_texts,\n",
    "            padding = True,\n",
    "            truncation = True,\n",
    "            return_tensors = 'pt',\n",
    "            max_length = 512\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "        penultimate_hidden_states = outputs.hidden_states[-2]\n",
    "\n",
    "        seq_lens = inputs['attention_mask'].sum(dim=-1) - 1\n",
    "\n",
    "        batch_size_curr = penultimate_hidden_states.shape[0]\n",
    "\n",
    "        last_token_embeddings = penultimate_hidden_states[\n",
    "            torch.arange(batch_size_curr, device = model.device),\n",
    "            seq_lens\n",
    "        ].float().cpu().numpy()\n",
    "        all_embeddings.append(last_token_embeddings)\n",
    "\n",
    "    return np.vstack(all_embeddings)\n",
    "\n",
    "\n",
    "def get_reps(\n",
    "    df, model, tokenizer, device, batch_size=1):\n",
    "    \n",
    "    embeddings = get_hidden_states(df = df, model = model, tokenizer = tokenizer, device = device, batch_size = batch_size)\n",
    "\n",
    "    annotated_df = df.copy()\n",
    "\n",
    "    annotated_df['representation'] = list(embeddings)\n",
    "\n",
    "    return annotated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb52626",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = make_template_format(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c535f91e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "full_rep_df = get_reps(df=df, model=model, tokenizer=tokenizer, device=device, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a5bb18",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "full_rep_df = full_rep_df[['title', 'question', 'answer', 'type', 'representation']]\n",
    "full_rep_df.head()\n",
    "\n",
    "df = full_rep_df.copy()\n",
    "df.to_parquet('./data/mix/coresets/moderate/dta_reps_moderate.parquet', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9629c9a8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "_, mod_1 = cluster_and_select_mod(\n",
    "    annotated_df = full_rep_df,\n",
    "    selection_percent = 0.01,\n",
    "    n_clusters = 4,\n",
    ")\n",
    "\n",
    "_, mod_2 = cluster_and_select_mod(\n",
    "    annotated_df = full_rep_df,\n",
    "    selection_percent = 0.02,\n",
    "    n_clusters = 4,\n",
    ")\n",
    "\n",
    "_, mod_5 = cluster_and_select_mod(\n",
    "    annotated_df = full_rep_df,\n",
    "    selection_percent = 0.05,\n",
    "    n_clusters = 4,\n",
    ")\n",
    "\n",
    "_, mod_10 = cluster_and_select_mod(\n",
    "    annotated_df = full_rep_df,\n",
    "    selection_percent = 0.1,\n",
    "    n_clusters = 4,\n",
    ")\n",
    "\n",
    "_, mod_20 = cluster_and_select_mod(\n",
    "    annotated_df = full_rep_df,\n",
    "    selection_percent = 0.2,\n",
    "    n_clusters = 4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c281e0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "mod_1.to_csv('./data/mix/coresets/moderate/mod_1.csv', index=False)\n",
    "mod_2.to_csv('./data/mix/coresets/moderate/mod_2.csv', index=False)\n",
    "mod_5.to_csv('./data/mix/coresets/moderate/mod_5.csv', index=False)\n",
    "mod_10.to_csv('./data/mix/coresets/moderate/mod_10.csv', index=False)\n",
    "mod_20.to_csv('./data/mix/coresets/moderate/mod_20.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
